{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPFs1ny4w7txE4wASo0bsY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elwing-Chou/tibaml0826/blob/main/sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FDJGSRcNsUkk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\n",
        "    fname=\"aclImdb.tar.gz\", \n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "    extract=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "def getdata(mid):\n",
        "    dn = os.path.dirname(dataset)\n",
        "    posfn = glob.glob(os.path.join(dn, \"aclImdb\", mid, \"pos\", \"*\"))\n",
        "    negfn = glob.glob(os.path.join(dn, \"aclImdb\", mid, \"neg\", \"*\"))\n",
        "    contents = []\n",
        "    for fn in posfn + negfn:\n",
        "        with open(fn, encoding=\"utf-8\") as f:\n",
        "            contents.append(f.read())\n",
        "    df = pd.DataFrame({\n",
        "        \"content\":contents,\n",
        "        \"sentiment\":[1] * len(posfn) + [0] * len(negfn)\n",
        "    })\n",
        "    return df\n",
        "train_df = getdata(\"train\")\n",
        "test_df = getdata(\"test\")"
      ],
      "metadata": {
        "id": "01q6WlGatI-R"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "DSYfCwwhuHVS",
        "outputId": "4d0f2cf6-1e2c-42c5-ae3f-3a592ec45410"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 content  sentiment\n",
              "0      After I've seen this movie I find it hard to u...          1\n",
              "1      I had never heard about this movie when it was...          1\n",
              "2      I really liked the first part of this film in ...          1\n",
              "3      Most of the criticism of \"Attack of Show\" is f...          1\n",
              "4      To my eternal shame, I've never seen a silent ...          1\n",
              "...                                                  ...        ...\n",
              "24995  The first film was quite hip and had amusing m...          0\n",
              "24996  Divorced single mom in picturesque seaside tow...          0\n",
              "24997  It's schmaltzy, but then what else did you exp...          0\n",
              "24998  What a shame. This could have been good. The m...          0\n",
              "24999  Following a 19th century gun dual that goes aw...          0\n",
              "\n",
              "[25000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b170551d-635c-40e6-bc4e-406894d32dcf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>After I've seen this movie I find it hard to u...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I had never heard about this movie when it was...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I really liked the first part of this film in ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Most of the criticism of \"Attack of Show\" is f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>To my eternal shame, I've never seen a silent ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>The first film was quite hip and had amusing m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>Divorced single mom in picturesque seaside tow...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>It's schmaltzy, but then what else did you exp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>What a shame. This could have been good. The m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>Following a 19th century gun dual that goes aw...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b170551d-635c-40e6-bc4e-406894d32dcf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b170551d-635c-40e6-bc4e-406894d32dcf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b170551d-635c-40e6-bc4e-406894d32dcf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D\n",
        "# 3001(3000種常用詞+1種填補)\n",
        "layers = [\n",
        "    # 300100 = 3001(種) * 100(weight)\n",
        "    Embedding(3001, 100, input_length=512, mask_zero=True),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(2, activation=\"softmax\")\n",
        "]\n",
        "model = Sequential(layers)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgiSP241viNy",
        "outputId": "2d4e8aa8-fcdb-4766-dd56-0dc77a79d59c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 512, 100)          300100    \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 100)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 300,302\n",
            "Trainable params: 300,302\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(loss=SparseCategoricalCrossentropy(),\n",
        "       optimizer=Adam(),\n",
        "       metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "AHj4DJQ20Lu5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. tokenize: 把詞化做index\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tok = Tokenizer(num_words=3000)\n",
        "tok.fit_on_texts(train_df[\"content\"])"
      ],
      "metadata": {
        "id": "1FMOAgdnSg4j"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 可以check一下\n",
        "# tok.word_index\n",
        "# tok.index_word"
      ],
      "metadata": {
        "id": "x7wSIqb2TceU"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_seq = tok.texts_to_sequences(train_df[\"content\"])\n",
        "x_test_seq = tok.texts_to_sequences(test_df[\"content\"])\n",
        "pd.DataFrame(x_train_seq)"
      ],
      "metadata": {
        "id": "XlZbR2rTT8kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 截長補短\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train_pad = pad_sequences(x_train_seq, maxlen=512)\n",
        "x_test_pad = pad_sequences(x_test_seq, maxlen=512)\n",
        "pd.DataFrame(x_train_pad)"
      ],
      "metadata": {
        "id": "4yWkxRjzXNS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_train = np.array(train_df[\"sentiment\"])\n",
        "y_test = np.array(test_df[\"sentiment\"])"
      ],
      "metadata": {
        "id": "qStiS2QBZcQh"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"imdb.h5\", save_best_only=True),\n",
        "    EarlyStopping(patience=5, restore_best_weights=True)\n",
        "]\n",
        "# 不想要進度條, verbose=2\n",
        "model.fit(x_train_pad,\n",
        "     y_train,\n",
        "     batch_size=200,\n",
        "     epochs=50,\n",
        "     validation_split=0.1,\n",
        "     callbacks=callbacks,\n",
        "     verbose=2)"
      ],
      "metadata": {
        "id": "b7B7HmDeZXvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test_pad, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSO6jOpwZ9SQ",
        "outputId": "7e0349a2-86c7-4c5f-dc84-636cae971b98"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 4s 6ms/step - loss: 0.2915 - accuracy: 0.8805\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.29148074984550476, 0.8804799914360046]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comment = input(\"comment:\")\n",
        "comment_tok = tok.texts_to_sequences([comment])\n",
        "comment_pad = pad_sequences(comment_tok, maxlen=512)\n",
        "pre = model.predict(comment_pad)[0]\n",
        "labels = [\"neg\", \"pos\"]\n",
        "for l, p in zip(labels, pre):\n",
        "    print(l, \"的機率:\", p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEJN_VyuaN0e",
        "outputId": "5c7323b0-19ba-4a62-db42-ecfb42b07b09"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comment:Whoever's thinking about watching this movie, don't. Absolute garbage.  They've ruined everything they had built since the first Iron man came out. Burned it to the ground. I am utterly disappointed and shocked.  This made me never wanna watch another Marvel movie again. Ever.  I was so excited about this movie, I couldn't wait for it to come out. Now, I can't find words to describe how terrible this movie was. This has ruined my day.\n",
            "neg 的機率: 0.99622214\n",
            "pos 的機率: 0.0037778444\n"
          ]
        }
      ]
    }
  ]
}